{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3bff3821-2500-4790-a993-3440752a3f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vt/bw9kl3vx6gzdh2yxm2cgfwsr0000gn/T/ipykernel_67491/1765894306.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  a_new_df2['assists'] = df_2020_2021['Assists']\n",
      "/var/folders/vt/bw9kl3vx6gzdh2yxm2cgfwsr0000gn/T/ipykernel_67491/1765894306.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  a_new_df2['goals_conceded'] = df_2020_2021['Goals_Conceded']\n",
      "/var/folders/vt/bw9kl3vx6gzdh2yxm2cgfwsr0000gn/T/ipykernel_67491/1765894306.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  a_new_df2['goals_scored'] = df_2020_2021['Goals_Scored']\n",
      "/var/folders/vt/bw9kl3vx6gzdh2yxm2cgfwsr0000gn/T/ipykernel_67491/1765894306.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  a_new_df2['clean_sheets'] = df_2020_2021['Clean_Sheets']\n",
      "/var/folders/vt/bw9kl3vx6gzdh2yxm2cgfwsr0000gn/T/ipykernel_67491/1765894306.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  a_new_df2['saves'] = df_2020_2021['Saves']\n",
      "/var/folders/vt/bw9kl3vx6gzdh2yxm2cgfwsr0000gn/T/ipykernel_67491/1765894306.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  a_new_df2['minutes'] = df_2020_2021['Minutes']\n",
      "/var/folders/vt/bw9kl3vx6gzdh2yxm2cgfwsr0000gn/T/ipykernel_67491/1765894306.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  a_new_df2['yellow_cards'] = df_2020_2021['Yellow_Cards']\n",
      "/var/folders/vt/bw9kl3vx6gzdh2yxm2cgfwsr0000gn/T/ipykernel_67491/1765894306.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  a_new_df2['red_cards'] = df_2020_2021['Red_Cards']\n",
      "/var/folders/vt/bw9kl3vx6gzdh2yxm2cgfwsr0000gn/T/ipykernel_67491/1765894306.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  a_new_df2['total_points'] = df_2020_2021['Total_Points']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming you have already loaded your data from CSVs into pandas DataFrames\n",
    "\n",
    "# Dummy data loading (replace with actual data loading)\n",
    "df_2023_2024 = pd.read_csv('2023-2024.csv')\n",
    "df_2020_2021 = pd.read_csv('2020-2021.csv')\n",
    "\n",
    "\n",
    "df_2022_2023= pd.read_csv('2022-2023.csv')\n",
    "\n",
    "\n",
    "selective_df_2023_2024=df_2023_2024[['assists', 'goals_conceded', 'goals_scored','clean_sheets','saves','minutes','yellow_cards','red_cards','total_points']]\n",
    "\n",
    "selective_df_2022_2023=df_2022_2023[['assists', 'goals_conceded', 'goals_scored','clean_sheets','saves','minutes','yellow_cards','red_cards','total_points']]\n",
    "\n",
    "selective_df_2022_2023=selective_df_2022_2023.astype(float)\n",
    "\n",
    "selective_df_2023_2024=selective_df_2023_2024.astype(float)\n",
    "\n",
    "df_2023_2024=pd.concat([selective_df_2023_2024, selective_df_2022_2023], axis=0)\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# df_2023_2024['name']=np.array(df_2023_2024['name']).reshape(-1,1)\n",
    "# df_2023_2024['position']=np.array(df_2023_2024['position']).reshape(-1,1)\n",
    "# df_2023_2024['team']=np.array(df_2023_2024['team']).reshape(-1,1)\n",
    "\n",
    "# df_2023_2024['name']=pd.DataFrame(encoder.fit_transform(df_2023_2024['name']))\n",
    "# df_2023_2024['position']=pd.DataFrame(encoder.fit_transform(df_2023_2024['position']))\n",
    "# df_2023_2024['team']=pd.DataFrame(encoder.fit_transform(df_2023_2024['team']))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# a_new_df1 = df_2023_2024[['assists', 'goals_conceded', 'goals_scored','clean_sheets','saves','minutes','yellow_cards','red_cards','total_points']]\n",
    "\n",
    "a_new_df2 = df_2020_2021[['Assists', 'Goals_Conceded', 'Goals_Scored', 'Clean_Sheets', 'Saves', 'Minutes', 'Yellow_Cards', 'Red_Cards', 'Total_Points']]\n",
    "# df_2020_2021[\"First_Name\"] = pd.DataFrame(encoder.fit_transform(df_2020_2021[\"First_Name\"]))\n",
    "# df_2020_2021[\"Second_Name\"] = pd.DataFrame(encoder.fit_transform(df_2020_2021[\"Second_Name\"]))\n",
    "\n",
    "\n",
    "\n",
    "# a_new_df3 = pd.DataFrame({'name': df_2020_2021[\"First_Name\"] + ' ' + df_2020_2021[\"Second_Name\"]})\n",
    "\n",
    "a_new_df2['assists'] = df_2020_2021['Assists']\n",
    "a_new_df2['goals_conceded'] = df_2020_2021['Goals_Conceded']\n",
    "a_new_df2['goals_scored'] = df_2020_2021['Goals_Scored']\n",
    "a_new_df2['clean_sheets'] = df_2020_2021['Clean_Sheets']\n",
    "a_new_df2['saves'] = df_2020_2021['Saves']\n",
    "a_new_df2['minutes'] = df_2020_2021['Minutes']\n",
    "a_new_df2['yellow_cards'] = df_2020_2021['Yellow_Cards']\n",
    "a_new_df2['red_cards'] = df_2020_2021['Red_Cards']\n",
    "a_new_df2['total_points'] = df_2020_2021['Total_Points']\n",
    "\n",
    "\n",
    "a_new_df2=a_new_df2.astype(float)\n",
    "\n",
    "# a_new_df3['position'] = pd.DataFrame(encoder.fit_transform(a_new_df2['position']))\n",
    "# a_new_df3['team'] = pd.DataFrame(encoder.fit_transform(a_new_df2['Club']))\n",
    "# a_new_df3['total_points'] = pd.DataFrame(encoder.fit_transform(a_new_df2['total_points']))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Assuming 'total_points' is the target variable\n",
    "entire_data = pd.concat([df_2023_2024, a_new_df2], axis=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc71199b-4d2a-40d0-bb50-2ac46a06e0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nX_train = torch.tensor(entire_data[['assists', 'goals_conceded', 'goals_scored','clean_sheets','saves','minutes','yellow_cards','red_cards']].values, dtype=torch.float32)  # Adjust shape as needed\\n# y_train = torch.tensor(training_data[['total_points']].values, dtype=torch.float32)  # Adjust shape as needed\\ny_train = torch.tensor(entire_data[['total_points']].values, dtype=torch.float32)  # Adjust shape as needed\\n\\nX_test = torch.tensor(entire_data[['assists', 'goals_conceded', 'goals_scored','clean_sheets','saves','minutes','yellow_cards','red_cards']].values, dtype=torch.float32)  # Adjust shape as needed\\ny_test = torch.tensor(entire_data[['total_points']].values, dtype=torch.float32)  # Adjust shape as needed\\n\\n# X_test = torch.tensor(testing_data[['assists', 'goals_conceded', 'goals_scored','clean_sheets','saves','minutes','yellow_cards','red_cards']].values, dtype=torch.float32)  # Adjust shape as needed\\n# y_test = torch.tensor(testing_data[['total_points']].values, dtype=torch.float32)  # Adjust shape as needed\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train_array, X_test_array, y_train_array, y_test_array = train_test_split(\n",
    "    entire_data[['assists', 'goals_conceded', 'goals_scored','clean_sheets','saves','minutes','yellow_cards','red_cards']].values,\n",
    "    entire_data[['total_points']].values,\n",
    "    test_size=0.01,\n",
    "    random_state=42)\n",
    "\n",
    "\n",
    "# print(X_train_array[0:5])\n",
    "# print(entire_data[['assists', 'goals_conceded', 'goals_scored','clean_sheets','saves','minutes','yellow_cards','red_cards']].values[0:5])\n",
    "# # print(type(X_train_array))\n",
    "# # print(type(entire_data[['assists', 'goals_conceded', 'goals_scored','clean_sheets','saves','minutes','yellow_cards','red_cards']].values))\n",
    "\n",
    "# print('_____________')\n",
    "# print(y_train_array[0:5])\n",
    "# print(entire_data[['total_points']].values[0:5])\n",
    "\n",
    "\n",
    "# print(X_test_array[0:5])\n",
    "# print(y_test_array[0:5])\n",
    "# print(entire_data[['assists', 'goals_conceded', 'goals_scored','clean_sheets','saves','minutes','yellow_cards','red_cards']].values[0:5])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# training_data = train_data['total_points']\n",
    "# testing_data = test_data[['assists', 'goals_conceded', 'goals_scored','clean_sheets','saves','minutes','yellow_cards','red_cards','total_points']].dropna()\n",
    "\n",
    "\n",
    "\n",
    "# Convert pandas series to PyTorch tensors\n",
    "X_train = torch.tensor(X_train_array, dtype=torch.float32)  # Adjust shape as needed\n",
    "y_train = torch.tensor(y_train_array, dtype=torch.float32)  # Adjust shape as needed\n",
    "X_test = torch.tensor(X_test_array, dtype=torch.float32)  # Adjust shape as needed\n",
    "y_test = torch.tensor(y_test_array, dtype=torch.float32)  # Adjust shape as needed\n",
    "\n",
    "\n",
    "# Convert pandas series to PyTorch tensors\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "X_train = torch.tensor(entire_data[['assists', 'goals_conceded', 'goals_scored','clean_sheets','saves','minutes','yellow_cards','red_cards']].values, dtype=torch.float32)  # Adjust shape as needed\n",
    "# y_train = torch.tensor(training_data[['total_points']].values, dtype=torch.float32)  # Adjust shape as needed\n",
    "y_train = torch.tensor(entire_data[['total_points']].values, dtype=torch.float32)  # Adjust shape as needed\n",
    "\n",
    "X_test = torch.tensor(entire_data[['assists', 'goals_conceded', 'goals_scored','clean_sheets','saves','minutes','yellow_cards','red_cards']].values, dtype=torch.float32)  # Adjust shape as needed\n",
    "y_test = torch.tensor(entire_data[['total_points']].values, dtype=torch.float32)  # Adjust shape as needed\n",
    "\n",
    "# X_test = torch.tensor(testing_data[['assists', 'goals_conceded', 'goals_scored','clean_sheets','saves','minutes','yellow_cards','red_cards']].values, dtype=torch.float32)  # Adjust shape as needed\n",
    "# y_test = torch.tensor(testing_data[['total_points']].values, dtype=torch.float32)  # Adjust shape as needed\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "449eebc8-f5dd-4ce5-b824-183956dd6e6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test loss: 2088.8961\n",
      "Epoch 1\n",
      "Average Test loss: 65.3281\n",
      "Epoch 2\n",
      "Average Test loss: 79.7586\n",
      "Epoch 3\n",
      "Average Test loss: 66.5195\n",
      "Epoch 4\n",
      "Average Test loss: 75.8995\n",
      "Epoch 5\n",
      "Average Test loss: 108.2784\n",
      "Epoch 6\n",
      "Average Test loss: 17.8331\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# DataLoader for training and testing\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "batch_size = 1\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Device configuration\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Define the neural network model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linear_stack = nn.Sequential(\n",
    "            nn.Linear(8, 300),  # Adjust input size if needed\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(300, 200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200, 100),  # Adjust input size if needed\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 50),  # Adjust input size if needed\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 1)  # Adjust input size if needed\n",
    "            \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        # print('xxxxxxxxx')\n",
    "        # print(x)\n",
    "        x = self.linear_stack(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = NeuralNetwork().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)  # Adjust learning rate as needed\n",
    "\n",
    "# Training function\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    for batch_idx, (data, targets) in enumerate(dataloader):\n",
    "        \n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(data)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Testing function\n",
    "def test(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data, targets in dataloader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            outputs = model(data)\n",
    "            test_loss += loss_fn(outputs, targets).item() * data.size(0)\n",
    "\n",
    "    test_loss /= len(dataloader.dataset)\n",
    "    print(f'Average Test loss: {test_loss:.4f}')\n",
    "    return test_loss\n",
    "\n",
    "# Training loop\n",
    "def fit(min_loss = 20 , patience_epoch = 100 ):\n",
    "    test_loss=test(test_dataloader, model, loss_fn)\n",
    "    epochs=1\n",
    "    while test_loss>= min_loss and epochs < patience_epoch:    \n",
    "        print(\"Epoch\", epochs)\n",
    "        epochs=epochs+1\n",
    "        train(train_dataloader, model, loss_fn, optimizer)\n",
    "        test_loss=test(test_dataloader, model, loss_fn)\n",
    "\n",
    "    print(\"Done!\")\n",
    "fit(20, 150)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
